{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d21162d1-10d2-4c28-b512-9366f6c3e0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(371785, 40, 39)\n",
      "(371785, 39)\n",
      "Epoch 1/4\n",
      "\u001b[1m1453/1453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 80ms/step - loss: 2.2496\n",
      "Epoch 2/4\n",
      "\u001b[1m1453/1453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 81ms/step - loss: 1.6118\n",
      "Epoch 3/4\n",
      "\u001b[1m1453/1453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 79ms/step - loss: 1.5112\n",
      "Epoch 4/4\n",
      "\u001b[1m1453/1453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 79ms/step - loss: 1.4586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x168f32990>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Load and process the text data\n",
    "filepath = tf.keras.utils.get_file('shakes.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "\n",
    "# Read the text file, decode to UTF-8, and convert to lowercase\n",
    "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()\n",
    "\n",
    "# Define parameters\n",
    "seq_length = 40\n",
    "STEP_SIZE = 3\n",
    "\n",
    "# Create character mapping\n",
    "characters = sorted(set(text))\n",
    "char_to_index = {c: i for i, c in enumerate(characters)}\n",
    "index_to_char = {i: c for i, c in enumerate(characters)}\n",
    "\n",
    "# Prepare input and output sequences\n",
    "sentences = []\n",
    "next_characters = []\n",
    "\n",
    "for i in range(0, len(text) - seq_length, STEP_SIZE):\n",
    "    sentences.append(text[i:i + seq_length])\n",
    "    next_characters.append(text[i + seq_length])\n",
    "\n",
    "# One-hot encode the input and output data\n",
    "x = np.zeros((len(sentences), seq_length, len(characters)), dtype=bool)\n",
    "y = np.zeros((len(sentences), len(characters)), dtype=bool)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, character in enumerate(sentence):\n",
    "        x[i, t, char_to_index[character]] = 1  # One-hot encode characters in the sequence\n",
    "    y[i, char_to_index[next_characters[i]]] = 1  # One-hot encode the next character\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(seq_length, len(characters))))\n",
    "model.add(Dense(len(characters)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01))\n",
    "\n",
    "# Print shapes of x and y\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Train the model\n",
    "model.fit(x, y, batch_size=256, epochs=4)\n",
    "\n",
    "# Save the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44004da6-a667-47ac-aedd-ed95b7563fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('poetic_text_generator.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19932549-4207-48cf-803e-380f3872d21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds + 1e-8) / temperature  # Apply temperature scaling\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)  # Normalize to get probabilities\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d471022-0aa7-4fd7-9815-ecdbb260996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(length , temperature):\n",
    "    start : random.randin(0 , len(text)- seq-length-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24d51d95-32ed-4323-9f04-d60ecb79c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(length, temperature=1.0):\n",
    "    # Ensure you start with a valid seed\n",
    "    start_index = np.random.randint(0, len(text) - seq_length - 1)\n",
    "    sentence = text[start_index: start_index + seq_length]\n",
    "    generated = sentence\n",
    "\n",
    "    # Generate `length` characters\n",
    "    for i in range(length):\n",
    "        # Create the input array (1, seq_length, len(characters))\n",
    "        x = np.zeros((1, seq_length, len(characters)))\n",
    "        \n",
    "        # One-hot encode the current sentence\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[0, t, char_to_index[char]] = 1\n",
    "        \n",
    "        # Predict the next character probabilities\n",
    "        predictions = model.predict(x, verbose=0)[0]\n",
    "        \n",
    "        # Sample the next character based on temperature\n",
    "        next_index = sample(predictions, temperature)\n",
    "        next_char = index_to_char[next_index]\n",
    "        \n",
    "        # Add the next character to the generated text\n",
    "        generated += next_char\n",
    "        \n",
    "        # Update the input sequence (shift left by 1)\n",
    "        sentence = sentence[1:] + next_char\n",
    "    \n",
    "    return generated  # Return the generated text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e980d53-b945-4bfe-9608-0b0e67cc15b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0.2---------\n",
      "me;\n",
      "and, by my troth, you have cause. your father.\n",
      "\n",
      "coriolanus:\n",
      "what, sir, i have mercutio, and so the death,\n",
      "and so shall be the son the stander of the poor soul to the man\n",
      "and that be this shall say i have so in the stand.\n",
      "\n",
      "buttaret:\n",
      "he shall say the son to the hands of his hand.\n",
      "\n",
      "coriolanus:\n",
      "the brother to my son the stand to man all t\n",
      "---------0.4---------\n",
      " language! heavens!\n",
      "i am the best of the greater latence his\n",
      "a what i may sleep the man all the sword\n",
      "than our england the own child the crown of will\n",
      "to so that say i think the father to your noble conscanor,\n",
      "and what do i have the crown to be this place.\n",
      "\n",
      "marcius:\n",
      "what swell me his honour will bring with his myself\n",
      "and say the roment of\n",
      "---------0.6---------\n",
      "not pay for the glasses you have burst?\n",
      "\n",
      "complayih:\n",
      "art is on the stone by good for a grandess will part\n",
      "the fall of my courtry up.\n",
      "\n",
      "first senator:\n",
      "sir, yet i did, a byour chair words,\n",
      "that well plase me sleep'd and death them:\n",
      "how now i see, and well the reason, the read here,\n",
      "thank the catesbing hath all the hold up marcue\n",
      "and make the \n",
      "---------0.8---------\n",
      "o, good sir, softly, good sir! i fear, sir, and that\n",
      "stinglh is such on the hurd on bride and me\n",
      "your love as jost in your fortune of thy\n",
      "heavens it all speit bream neashoresting,\n",
      "and in him, and steel did wellow of where and so's.\n",
      "\n",
      "paulina:\n",
      "o holy, for weary: make beins, i have me\n",
      "this art thoughts art in a son the news it.\n",
      "i they rove o\n",
      "---------1---------\n",
      "o five and twenty thousand,\n",
      "why, via! to sil. warwick dear is your jook'd this wain.\n",
      "how not too conjurch earth is?\n",
      "\n",
      "baptipts:\n",
      "all think to harp! what; so conscpanio?\n",
      "was a his sturn'd fold, up i say.\n",
      "\n",
      "paris:\n",
      "slaleht a day? i think it sims, set in my\n",
      "but judgen world, so carilus that your kit\n",
      "his myself empure's greacence me: as spedeer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---------0.2---------')\n",
    "print(generate_text(300, 0.2))\n",
    "\n",
    "print('---------0.4---------')\n",
    "print(generate_text(300, 0.4))\n",
    "\n",
    "print('---------0.6---------')\n",
    "print(generate_text(300, 0.6))\n",
    "\n",
    "print('---------0.8---------')\n",
    "print(generate_text(300, 0.8))\n",
    "\n",
    "print('---------1---------')\n",
    "print(generate_text(300, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fef05bc-2353-40c6-8825-45f8671fdd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text:\n",
      "  heat of blood.\n",
      "and lack of temper'd judget your honour confect\n",
      "to his peace and reaton'd the supptition's after.\n",
      "\n",
      "mercutio:\n",
      "what, marricy have i do the man and the store.\n",
      "\n",
      "second servant:\n",
      "these word here of rowars, at his swearful:\n",
      "when i have not thy son horses worship,\n",
      "what the son to the courted all of him.\n",
      "\n",
      "aufidius:\n",
      "what, sir here, \n"
     ]
    }
   ],
   "source": [
    "start_text = \"In the quiet of the night, \"  # Your seed text\n",
    "generated_text = generate_text( length=300, temperature=0.5)\n",
    "print(\"Generated Text:\\n\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261daf1f-190b-41ff-a033-b94844acef82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
